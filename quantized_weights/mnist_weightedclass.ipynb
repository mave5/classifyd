{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing how weighted class works in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 2: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline \n",
    "from numpy import linalg as LA\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model(params):\n",
    "    lr=params['lr']\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, 28, 28),\n",
    "    activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (60000, 1, 28, 28) (60000, 10)\n",
      "data shape (10000, 1, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print 'data shape', X_train.shape,y_train.shape\n",
    "print 'data shape', X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait to train ...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 30, 24, 24)    780         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 30, 12, 12)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 15, 10, 10)    4065        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 5, 5)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 15, 5, 5)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 375)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           48128       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            6450        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 59933\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print 'wait to train ...'\n",
    "\n",
    "params={'lr': 1e-3}\n",
    "# build the model\n",
    "model = larger_model(params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.3509 - acc: 0.8064 - val_loss: 1.3484 - val_acc: 0.8882\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0859 - acc: 0.8852 - val_loss: 1.2937 - val_acc: 0.8964\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0611 - acc: 0.8916 - val_loss: 1.3620 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0497 - acc: 0.8951 - val_loss: 1.3462 - val_acc: 0.9012\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0430 - acc: 0.8976 - val_loss: 1.3750 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0379 - acc: 0.8989 - val_loss: 1.3300 - val_acc: 0.9029\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0341 - acc: 0.8998 - val_loss: 1.3742 - val_acc: 0.9043\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0304 - acc: 0.9008 - val_loss: 1.3719 - val_acc: 0.9033\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0295 - acc: 0.9012 - val_loss: 1.3365 - val_acc: 0.9045\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.0246 - acc: 0.9026 - val_loss: 1.4155 - val_acc: 0.9040\n",
      "Baseline Error: 9.60%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "cw={0:1, 1:1, 2:1,3:1,4:1,5:0,6:1,7:1,8:1,9:1}\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200,verbose=1,class_weight=cw)\n",
    "\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s\n",
      " accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score,accuracy=model.evaluate(X_test,y_test)\n",
    "print '\\n accuracy: %.2f' %accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
